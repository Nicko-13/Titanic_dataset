{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Titanic problem\n",
    "\n",
    "## Problem definition\n",
    "- Informal: predict passengers who survived and who died;\n",
    "- Formal:\n",
    "    - Task: create a binary classifier algorythm which classify a passenger from Titanic as survivied or not;\n",
    "    - Experience: data on Titanic wreck;\n",
    "    - Performance: accuracy score;\n",
    "    \n",
    "## Assumptions\n",
    "- Columns wise assumption:\n",
    "    - Pclass: unequal treatment of different classes of passengers(first class is the top priority);\n",
    "    - Sex and age: women and children were rescued first;\n",
    "    - SibSp: there might be two possible situations: man can help woman to survive, or they decided to die together;\n",
    "    - Parch: the parents can help children to survive;\n",
    "    - Fare: the steerage passengers had the lowest chance to survive (the cheapest tickets).\n",
    "        - First Class (parlor suite) — £870;\n",
    "        - First Class (berth)— £30;\n",
    "        - Second Class — £12;\n",
    "        - Third Class — £3 to £8;\n",
    "    - Cabin: the evacution was from boat deck. The nearer a passenger was to this deck the greater chance to survive;\n",
    "    - Embarked: the English speaking passengerns had more chance to survive. The embarked place may have impact on it. S-England, C-France, Q-Ireland (English language).\n",
    "- The dataset contains information only on passengers;\n",
    "- The dataset contains information only on passengers who were aboard during the accident;\n",
    "- The title of the passenger can matter for survival;\n",
    "\n",
    "## Solution\n",
    "- Data Selection:\n",
    "    - Pclass, Sex and Age: it is the widely known fact that the different classes of passengers were treated unequally. Also, the women and children were rescued first;\n",
    "    - SibSp and Parch: check if there is a statistically significant difference in survived and not survived groups;\n",
    "    - Ticket and Fare: cannot be used itself, however it might be helpful to identify the missing values of cabins;\n",
    "    - Cabin: see Assumptions section;\n",
    "    - Embarked: the chance to survive depended on language of the passenger. The people who embarked in France might not speak English;\n",
    "- Removing missing values in the following columns:\n",
    "    - Age: build a binary classifier to predict age group;\n",
    "    - Cabin: the decision was made to skip this feature as the number of missing values in train and holdout datasets is significant;\n",
    "    - Embarked: will be filled with mode;\n",
    "- Explore relationships between variables:\n",
    "    - Is there statistically significant difference in survival rate between passenger who had siblings/spouses aboard and didn't have; Who had parents/children aboard? Who had specific title?\n",
    "    - Is there statistically significant difference in survial rate between different ports?\n",
    "    - Is there statistically significant difference in class between different ports;\n",
    "- Features generation:\n",
    "    - Last name, first name, title, spouse ID from Name column;\n",
    "    - Fist class, Third class(dummies) from Pclass;\n",
    "    - Female (dummy) from Sex;\n",
    "    - S, Q (dummies) from Embarked;\n",
    "    - SibSp (dummies) from SibSp/NoSibsp;\n",
    "    - Parch (dummies) from Parch/NoParch;\n",
    "    - Adult man from Sex and Age;\n",
    "- Model fitting and optimization:\n",
    "    - Method parameters: train, validation, algo, params(dict);\n",
    "    - Method algo:\n",
    "        - Fit model to the train set;\n",
    "        - Make predictions;\n",
    "        - Calculate metric;\n",
    "        - Print information;\n",
    "- Model tunning:\n",
    "    - Method parameters: train, validation, algo, params;\n",
    "    - Method algo:\n",
    "        - Fit model to the train set;\n",
    "        - Make predictions;\n",
    "        - Calculate metric;\n",
    "        - Print information;\n",
    "        \n",
    "## Software development\n",
    "- Class Titanic_Dataset:\n",
    "    - Take Pandas DataFrames train and holdout as a parameters;\n",
    "    - Divide df to train and validation parts;\n",
    "    - Store train, validation and holdout dfs;\n",
    "    - Inherit all methods from Pandas Dataframe class;\n",
    "- Filling missing values:\n",
    "    - Embarked (9)\n",
    "    - Age (11);\n",
    "- Feature generation:\n",
    "    - First class (1, dummy);\n",
    "    - Third class (2, dummy);\n",
    "    - Last name from Name (3);\n",
    "    - First name from Name (4);\n",
    "    - Title from Name (5);\n",
    "    - Female (6, dummy);\n",
    "    - SibSp/NoSibsp from SibSp (7, dummy);\n",
    "    - Parch/NoParch from Parch (8, dummy);\n",
    "    - Cherbourg from Embarked (10, dummy);\n",
    "    - Adult man from Sex and Age (12, dummy);\n",
    "- Data visualization and statistical exploration (if nessecary):\n",
    "    - Survival rate Sibsp vs NoSibsp(14);\n",
    "    - Survival rate Parch vs NoParch(15);\n",
    "    - Survial rate between different titles (16);\n",
    "    - Survial rate between different ports (17);\n",
    "    - Class between different ports (18);\n",
    "- Model fitting and optimization;\n",
    "    - Algo (19);\n",
    "- Model tunning;\n",
    "    - Algo (20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age prediction problem\n",
    "\n",
    "### Problem definition\n",
    "- Informal: identify if the passenger is child or not;\n",
    "- Formal:\n",
    "    - Task: build a binary classifier to predict age group of passengers;\n",
    "    - Experience: data on Titanic passengers where the age not missed;\n",
    "    - Performance: ROC-AUC score;\n",
    "    \n",
    "### Assumptions\n",
    "- According to Encyclopedia Titanica the person was treated as a child if he/she was 14 years old or younger;\n",
    "- Is there any difference between number of children among:\n",
    "    - Different classes of passengers;\n",
    "    - Different genders;\n",
    "    - Different titles;\n",
    "    - passengers who has sibsp/parch aboard;\n",
    "    - Different ports;\n",
    "    \n",
    "### Solution\n",
    "- Create the same dummy variables as for titanic problem;\n",
    "- Check relationships between different variables and age group;\n",
    "- Build binary classifier to predict age group;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Thayer)  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB, ComplementNB\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('max_columns', 160)\n",
    "pd.set_option('max_rows', 800)\n",
    "pd.set_option('max_colwidth', 5000)\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "holdout = pd.read_csv('test.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of supporting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define funuction for name processing\n",
    "def process_mrs_with_par(name):\n",
    "    \"\"\"(str) -> str\n",
    "    \n",
    "    Return first name of the name for Mrs and Lady passengers whose first name is\n",
    "    in the parentheses.\n",
    "    \n",
    "    >>> process_mrs_with_par('Futrelle, Mrs. Jacques Heath (Lily May Peel)')\n",
    "    'Lily May Peel'\n",
    "    >>> process_mrs_with_par('Watt, Mrs. James (Elizabeth \"Bessie\" Inglis Milne)')\n",
    "    'Elizabeth Inglis Milne'\n",
    "    >>> process_mrs_with_par('Duff Gordon, Lady. (Lucille Christiana Sutherland) (\"Mrs Morgan\")')\n",
    "    'Lucille Christiana Sutherland'\n",
    "    \"\"\"\n",
    "    # extract the string within first parentheses without them\n",
    "    first_name = re.search('\\((.*?)\\)', name).group(1)\n",
    "       \n",
    "    # if resulting string contains string in quotes\n",
    "    if re.search('\"(.*)\"', first_name):\n",
    "         # remove part in quoutes from it\n",
    "        first_name = re.sub(' \"(.*)\"', '', first_name)\n",
    "    return first_name\n",
    "\n",
    "def process_other_names(name):\n",
    "    \"\"\"(str) -> str\n",
    "    \n",
    "    Return first name from name. \n",
    "    \n",
    "    >>> process_name('Sawyer, Mr. Frederick Charles')\n",
    "    'Frederick Charles'\n",
    "    >>> process_other_names('Bradley, Mr. George (\"George Arthur Brayton\")')\n",
    "    'George'\n",
    "    >>> process_other_names('Petranec, Miss. Matilda')\n",
    "    'Matilda'\n",
    "    >>> process_other_names('O\\\\'Dwyer, Miss. Ellen \"Nellie\"')\n",
    "    'Ellen'\n",
    "    >>> process_other_names('Masselmani, Mrs. Fatima')\n",
    "    'Fatima'\n",
    "    \"\"\"\n",
    "    #return all characters after dot or all characters between dot and parentheses or\n",
    "    # quotes\n",
    "    first_name = re.search('\\.(.*)', name).group(1)\n",
    "    # if string contains '(' or '\"':\n",
    "    if re.search('[(\"](.*)[)\"]', first_name):\n",
    "        # return all characters between '. ' and ' (' or ' \"'\n",
    "        first_name = re.sub('[(\"](.*)[)\"]', \"\", first_name)\n",
    "    return first_name\n",
    "\n",
    "def process_name(name):\n",
    "    \"\"\"(str) -> str\n",
    "    \n",
    "    Return first name from name. If title Mrs return name in parentheses without them.\n",
    "    Else return name before parentheses or all characters.\n",
    "    \n",
    "    >>> process_name('Sawyer, Mr. Frederick Charles')\n",
    "    'Frederick Charles'\n",
    "    >>> process_name('Bradley, Mr. George (\"George Arthur Brayton\")')\n",
    "    'George'\n",
    "    >>> process_name('Petranec, Miss. Matilda')\n",
    "    'Matilda'\n",
    "    >>> process_name('O\\\\'Dwyer, Miss. Ellen \"Nellie\"')\n",
    "    'Ellen'\n",
    "    >>> process_name('Futrelle, Mrs. Jacques Heath (Lily May Peel)')\n",
    "    'Lily May Peel'\n",
    "    >>> process_name('Watt, Mrs. James (Elizabeth \"Bessie\" Inglis Milne)')\n",
    "    'Elizabeth Inglis Milne'\n",
    "    >>> process_name('Duff Gordon, Lady. (Lucille Christiana Sutherland) (\"Mrs Morgan\")')\n",
    "    'Lucille Christiana Sutherland'\n",
    "    >>> process_name('Masselmani, Mrs. Fatima')\n",
    "    'Fatima'\n",
    "    \"\"\"\n",
    "    if re.search('Mrs|Lady', name):\n",
    "        try:\n",
    "            first_name = process_mrs_with_par(name)\n",
    "        except AttributeError:\n",
    "            first_name = process_other_names(name)\n",
    "    else:\n",
    "        first_name = process_other_names(name)\n",
    "    \n",
    "    return first_name.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of Titanic_Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Titanic_Dataset():\n",
    "    \n",
    "    @classmethod\n",
    "    def __init__(self, train_data, holdout_data):\n",
    "        self.train = train_data[['PassengerId', 'Pclass', 'Name',\n",
    "                           'Sex', 'Age', 'SibSp', 'Parch',\n",
    "                           'Ticket', 'Fare', 'Cabin',\n",
    "                           'Embarked', 'Survived']].copy()\n",
    "        self.holdout = holdout_data.copy()\n",
    "    \n",
    "    @classmethod\n",
    "    def get_dummy(self, col, value, new_name, comp=False):\n",
    "        # Create dummy variable from a given column with value as 1\n",
    "        # name new_name\n",
    "        try:\n",
    "            for df in (self.train, self.holdout):\n",
    "                if not comp:\n",
    "                    df[new_name] = df[col].apply(lambda x: 1 if x == value else 0)\n",
    "                else:\n",
    "                    df[new_name] = df[col].apply(lambda x: 1 if x > value else 0)\n",
    "        except KeyError:\n",
    "            pass\n",
    "            \n",
    "    @classmethod\n",
    "    def parse_name(self):\n",
    "        # Parse name column to last_name, title and first_name columns\n",
    "        for df in (self.train, self.holdout):\n",
    "            # Create last_name column\n",
    "            df['last_name'] = df['Name'].apply(lambda x: re.search('(.*)\\,', x).group(1))\n",
    "            # Create title column\n",
    "            df['title'] = df['Name'].apply(lambda x: re.search('\\, (.*)\\.', x).group(1))\n",
    "            # Create first_name column\n",
    "            df['first_name'] = df['Name'].apply(process_name)\n",
    "    \n",
    "    @classmethod\n",
    "    def fill_embarked(self):\n",
    "        self.train['Embarked'].fillna(self.train['Embarked'].mode()[0], inplace=True)\n",
    "        self.holdout['Embarked'].fillna(self.holdout['Embarked'].mode()[0], inplace=True)\n",
    "    \n",
    "    @classmethod\n",
    "    def drop_columns(self, columns):\n",
    "        for df in (self.train, self.holdout):\n",
    "            df.drop(columns, axis=1, inplace=True)\n",
    "    \n",
    "    @classmethod\n",
    "    def exp_rel(self, var):\n",
    "        values = self.train[var].unique()\n",
    "        f = lambda x: 1 if x <= 3 else math.ceil(x / 3)\n",
    "        fig = plt.figure(figsize=(9, 3*f(len(values))))\n",
    "        for i, value in enumerate(sorted(values)):\n",
    "            fig.add_subplot(f(len(values)), 3, i+1)\n",
    "            data = self.train[self.train[var]==value]\n",
    "            chart = sns.barplot(x='is_adult', y=\"is_adult\",data=data,\n",
    "                             estimator=lambda x: len(x) / len(data) * 100)\n",
    "            chart.tick_params(bottom=False, top=False, left=False, right=False)\n",
    "            chart.axes.get_yaxis().set_visible(False)\n",
    "            plt.xlabel('')\n",
    "            plt.ylabel('')\n",
    "            plt.title('Value of variable: ' + str(value))\n",
    "            plt.suptitle('The variable is ' + var, y=1.1, fontsize=15)\n",
    "            sides = ['left', 'right', 'top']\n",
    "            for side in sides:\n",
    "                chart.spines[side].set_visible(False)\n",
    "            for p in chart.patches:\n",
    "                chart.annotate(str(np.round(p.get_height(),\n",
    "                                            decimals=2)) + '%',\n",
    "                               (p.get_x() + p.get_width()/2,\n",
    "                                p.get_height() + 1),\n",
    "                               horizontalalignment='center')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    @staticmethod\n",
    "    def balance(data, col):\n",
    "        # Find value with the smalles number\n",
    "        smallest = min(data[col].value_counts().values)\n",
    "        # Find the number of rows to resample\n",
    "        num_resample = max(data[col].value_counts().values) - smallest\n",
    "        # Resample rows\n",
    "        sample = data.sample(num_resample, replace=True, random_state=1)\n",
    "        # return new dataset with resampled rows\n",
    "        return pd.concat([data, sample], axis=0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def sens_spec_score(true_labels, predictions):\n",
    "        tn, fp, fn, tp = confusion_matrix(true_labels, predictions).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn+fp)\n",
    "        return sensitivity, specificity\n",
    "    \n",
    "    @classmethod\n",
    "    def fit_and_optimize(self, model, X, y, bln=False):\n",
    "        # Divide dataset to train and validation parts\n",
    "        self.train_fit, self.test_fit = train_test_split(self.train[X + y], test_size=0.33)\n",
    "        if bln:\n",
    "            self.train_fit = self.balance(self.train_fit, y[0])\n",
    "        \n",
    "        # Use k-fold validation\n",
    "        kf = KFold(10, shuffle=True)\n",
    "        \n",
    "        roc_score = list()\n",
    "        sens_score = list()\n",
    "        spec_score = list()\n",
    "        for train_index, test_index in kf.split(self.train_fit):\n",
    "            # Fit model to the train set\n",
    "            fold_train = self.train_fit.iloc[train_index]\n",
    "            fold_test = self.train_fit.iloc[test_index]\n",
    "            model.fit(fold_train[X], fold_train[y])\n",
    "            # Make predictions;\n",
    "            predictions = model.predict(fold_test[X])\n",
    "            # Calculate metric;\n",
    "            roc_score.append(roc_auc_score(fold_test[y], predictions))\n",
    "            sens, spec = self.sens_spec_score(fold_test[y], predictions)\n",
    "            sens_score.append(sens)\n",
    "            spec_score.append(spec)\n",
    "        # Find the average metric and print it\n",
    "        print('Average ROC-AUC {1}; Model: {0}'.format(type(model).__name__,\n",
    "                                                       np.round(np.mean(roc_score), 5)))\n",
    "        print('Average Sensitivity {}'.format(np.round(np.mean(sens_score), 5)))\n",
    "        print('Average Specificity {}'.format(np.round(np.mean(spec_score), 5)))\n",
    "        return self.train_fit[X + y], self.test_fit[X + y] \n",
    "    \n",
    "    def tunning(self, model, grid_params, X, y):\n",
    "        # Instantiate the grid search model\n",
    "        grid_search = GridSearchCV(estimator = model,\n",
    "                                   scoring = 'roc_auc',\n",
    "                                   param_grid = grid_params, \n",
    "                                   cv = 5)\n",
    "        # Fit the grid search to the data\n",
    "        grid_search.fit(self.train_fit[X], self.train_fit[y])\n",
    "        # fit model with best parameters\n",
    "        model = grid_search.best_estimator_\n",
    "        # make predictions\n",
    "        model.fit(self.train_fit[X], self.train_fit[y])\n",
    "        predictions = model.predict(self.test_fit[X])\n",
    "        # calculate sensitivity and specificity\n",
    "        sens, spec = self.sens_spec_score(self.test_fit[y], predictions)\n",
    "        # print results\n",
    "        print('ROC-AUC {}'.format(roc_auc_score(self.test_fit[y], predictions)))\n",
    "        print('Sensitivity {}'.format(sens))\n",
    "        print('Specificity {}'.format(spec))\n",
    "        print(grid_search.best_params_)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train = train.copy()\n",
    "test_holdout = holdout.copy()\n",
    "titanic = Titanic_Dataset(test_train, test_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling missing values in age column\n",
    "\n",
    "First, we will initiliaze object of Titanic Dataset class and add various dummy columns in the data sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate class object\n",
    "age = Titanic_Dataset(train[~train['Age'].isnull()],\n",
    "                      train[train['Age'].isnull()].drop('Age', axis=1))\n",
    "\n",
    "# Add column is_1class\n",
    "age.get_dummy('Pclass', 1, 'is_1class')\n",
    "# Add column is_3class\n",
    "age.get_dummy('Pclass', 3, 'is_3class')\n",
    "# Add columns last_name, title, first_name\n",
    "age.parse_name()\n",
    "# Add column is_female\n",
    "age.get_dummy('Sex', 'female', 'is_female')\n",
    "# Add column have_sibsp\n",
    "age.get_dummy('SibSp', 0, 'have_sibsp', comp=True)\n",
    "# Add column have_parch\n",
    "age.get_dummy('Parch', 0, 'have_parch', comp=True)\n",
    "# Add column cher\n",
    "age.get_dummy('Embarked', 'C', 'cher')\n",
    "# Add column sout\n",
    "age.get_dummy('Embarked', 'S', 'sout')\n",
    "# Add column is_adult which is target variable for this part\n",
    "age.get_dummy('Age', 14, 'is_adult', comp=True)\n",
    "age.fill_embarked()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we will create bar charts to explore relationship between different variables and target variable. The special method will be defined for the visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
       "       'Ticket', 'Fare', 'Cabin', 'Embarked', 'Survived', 'is_1class',\n",
       "       'is_3class', 'last_name', 'title', 'first_name', 'is_female',\n",
       "       'have_sibsp', 'have_parch', 'cher', 'sout', 'is_adult'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age.train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    0.768362\n",
      "1    0.169492\n",
      "2    0.062147\n",
      "Name: Pclass, dtype: float64\n",
      "male      0.700565\n",
      "female    0.299435\n",
      "Name: Sex, dtype: float64\n",
      "0    0.774011\n",
      "1    0.146893\n",
      "8    0.039548\n",
      "3    0.022599\n",
      "2    0.016949\n",
      "Name: SibSp, dtype: float64\n",
      "0    0.887006\n",
      "2    0.067797\n",
      "1    0.045198\n",
      "Name: Parch, dtype: float64\n",
      "S    0.508475\n",
      "Q    0.276836\n",
      "C    0.214689\n",
      "Name: Embarked, dtype: float64\n",
      "0    0.830508\n",
      "1    0.169492\n",
      "Name: is_1class, dtype: float64\n",
      "1    0.768362\n",
      "0    0.231638\n",
      "Name: is_3class, dtype: float64\n",
      "Mr        0.672316\n",
      "Miss      0.203390\n",
      "Mrs       0.096045\n",
      "Master    0.022599\n",
      "Dr        0.005650\n",
      "Name: title, dtype: float64\n",
      "0    0.700565\n",
      "1    0.299435\n",
      "Name: is_female, dtype: float64\n",
      "0    0.774011\n",
      "1    0.225989\n",
      "Name: have_sibsp, dtype: float64\n",
      "0    0.887006\n",
      "1    0.112994\n",
      "Name: have_parch, dtype: float64\n",
      "0    0.785311\n",
      "1    0.214689\n",
      "Name: cher, dtype: float64\n",
      "1    0.508475\n",
      "0    0.491525\n",
      "Name: sout, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# cols = ['Pclass', 'Sex', 'Embarked', 'is_1class',\n",
    "#         'is_3class', 'have_sibsp', 'have_parch', 'cher', 'sout']\n",
    "cols = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked', 'is_1class',\n",
    "        'is_3class', 'title', 'is_female', 'have_sibsp', 'have_parch',\n",
    "        'cher', 'sout']\n",
    "for col in cols:\n",
    "    print(age.holdout[col].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional probabilities\n",
      "3    302\n",
      "1    181\n",
      "2    154\n",
      "Name: Pclass, dtype: int64\n",
      "\n",
      "3    53\n",
      "2    19\n",
      "1     5\n",
      "Name: Pclass, dtype: int64\n",
      "\n",
      "Common probabilities\n",
      "3    355\n",
      "1    186\n",
      "2    173\n",
      "Name: Pclass, dtype: int64\n",
      "<---------------------------------------->\n"
     ]
    }
   ],
   "source": [
    "prob_cols = ['Pclass']#, 'Sex', 'SibSp', 'Parch', 'title']\n",
    "for col in prob_cols:\n",
    "    print('Conditional probabilities')\n",
    "    print(age.train[age.train['is_adult']==1][col].value_counts())\n",
    "    print()\n",
    "    \n",
    "    print(age.train[age.train['is_adult']==0][col].value_counts())\n",
    "    print()\n",
    "    \n",
    "    print('Common probabilities')\n",
    "    print(age.train[col].value_counts())\n",
    "    print('<---------------------------------------->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "The percentage of children is different for the variables Pclass, Sex, is_1class, is_3class, have_sibsp, have_parch. As the variables Pclass and is_1class, is_3class correspond to the same data only dummy variables is_1class and is_3class will be used. For Sex variable the column is_female will be used. We can also notice that the dataset is imbalanced on 'is_adult ' column. The special method will be added to tackle this situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC-AUC 0.58844; Model: LogisticRegression\n",
      "Average Sensitivity 0.96689\n",
      "Average Specificity 0.21\n",
      "Average ROC-AUC 0.53491; Model: DecisionTreeClassifier\n",
      "Average Sensitivity 0.94721\n",
      "Average Specificity 0.12262\n",
      "Average ROC-AUC 0.68138; Model: RandomForestClassifier\n",
      "Average Sensitivity 0.94998\n",
      "Average Specificity 0.41278\n",
      "Average ROC-AUC 0.69263; Model: MLPClassifier\n",
      "Average Sensitivity 0.94985\n",
      "Average Specificity 0.4354\n",
      "Average ROC-AUC 0.49783; Model: SVC\n",
      "Average Sensitivity 0.99565\n",
      "Average Specificity 0.0\n",
      "Average ROC-AUC 0.75014; Model: BernoulliNB\n",
      "Average Sensitivity 0.91968\n",
      "Average Specificity 0.5806\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "X = ['is_1class', 'is_3class', 'is_female', 'have_sibsp', 'have_parch']\n",
    "y = ['is_adult']\n",
    "\n",
    "for model in [LogisticRegression(), DecisionTreeClassifier(),\n",
    "             RandomForestClassifier(), MLPClassifier(), SVC(), BernoulliNB()]:\n",
    "    age.fit_and_optimize(model, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BernoulliNB algorithm showed the best results. We will try to balance dataset in order to improve overall performance.  \n",
    "\n",
    "### Imporving overall performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC-AUC 0.59482; Model: LogisticRegression\n",
      "Average Sensitivity 0.96881\n",
      "Average Specificity 0.22083\n",
      "Average ROC-AUC 0.70796; Model: DecisionTreeClassifier\n",
      "Average Sensitivity 0.94692\n",
      "Average Specificity 0.46899\n",
      "Average ROC-AUC 0.74118; Model: RandomForestClassifier\n",
      "Average Sensitivity 0.95562\n",
      "Average Specificity 0.52673\n",
      "Average ROC-AUC 0.80454; Model: MLPClassifier\n",
      "Average Sensitivity 0.9314\n",
      "Average Specificity 0.67768\n",
      "Average ROC-AUC 0.5; Model: SVC\n",
      "Average Sensitivity 1.0\n",
      "Average Specificity 0.0\n",
      "Average ROC-AUC 0.7584; Model: BernoulliNB\n",
      "Average Sensitivity 0.93176\n",
      "Average Specificity 0.58503\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "for model in [LogisticRegression(), DecisionTreeClassifier(),\n",
    "             RandomForestClassifier(), MLPClassifier(), SVC(), BernoulliNB()]:\n",
    "    age.fit_and_optimize(model, X, y, bln=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that resampling has imporved performance of every model. The short list of models which will be used for further analysis:\n",
    "- RandomForestClassifier;\n",
    "- MLPClassifier;\n",
    "- BernoulliNB;\n",
    "\n",
    "### Algorithms tuning\n",
    "\n",
    "Let's update our class with new method for model tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC 0.6817275747508306\n",
      "Sensitivity 0.9348837209302325\n",
      "Specificity 0.42857142857142855\n",
      "{'criterion': 'gini', 'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "grid_params = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [10, 20, 30, 50, 100, None],\n",
    "    'min_samples_split': [2, 3, 5],\n",
    "    'min_samples_leaf': [1, 2, 3],           \n",
    "              }\n",
    "rf_best = age.tunning(RandomForestClassifier(), grid_params, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC 0.7775193798449613\n",
      "Sensitivity 0.8883720930232558\n",
      "Specificity 0.6666666666666666\n",
      "{'activation': 'tanh', 'hidden_layer_sizes': (50, 10)}\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "grid_params = {\n",
    "    'hidden_layer_sizes': [(50, 30), (50, 20), (50, 10)],\n",
    "    'activation':['identity', 'logistic', 'tanh', 'relu']\n",
    "              }\n",
    "nn_best = age.tunning(MLPClassifier(), grid_params, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC 0.7055370985603543\n",
      "Sensitivity 0.9348837209302325\n",
      "Specificity 0.47619047619047616\n",
      "{'alpha': 1.5, 'fit_prior': True}\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "grid_params = {\n",
    "    'alpha': [1.5, 2, 2.5, 3, 3.5],\n",
    "    'fit_prior': [True, False]\n",
    "    }\n",
    "nb_best = age.tunning(BernoulliNB(), grid_params, X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
